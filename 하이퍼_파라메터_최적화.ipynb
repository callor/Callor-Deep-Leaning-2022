{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/callor/Callor-DeepLearning-2022/blob/master/%ED%95%98%EC%9D%B4%ED%8D%BC_%ED%8C%8C%EB%9D%BC%EB%A9%94%ED%84%B0_%EC%B5%9C%EC%A0%81%ED%99%94.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23abee76",
      "metadata": {
        "id": "23abee76"
      },
      "source": [
        "이렇게 하려면 케라스 모델을 사이킷런 추정기처럼 보이게 바꿔야합니다.<br>\n",
        "먼저 일련의 하이퍼파라미터로 케라스 모델을 만들고 컴파일하는 함수를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a42960e9",
      "metadata": {
        "id": "a42960e9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "df6687a5",
      "metadata": {
        "id": "df6687a5"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "587a210a",
      "metadata": {
        "id": "587a210a"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f8ec9593",
      "metadata": {
        "id": "f8ec9593"
      },
      "outputs": [],
      "source": [
        "housing = fetch_california_housing()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "815bba5b",
      "metadata": {
        "id": "815bba5b"
      },
      "outputs": [],
      "source": [
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "X_new = X_test[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "765de17a",
      "metadata": {
        "id": "765de17a"
      },
      "outputs": [],
      "source": [
        "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
        "    for layer in range(n_hidden):\n",
        "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
        "    model.add(keras.layers.Dense(1))\n",
        "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "    model.compile(loss='mse', optimizer=optimizer)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21004c43",
      "metadata": {
        "id": "21004c43"
      },
      "source": [
        "build_model() 함수를 사용해 KerasRegressor 클래스 객체를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "66656bfb",
      "metadata": {
        "scrolled": true,
        "id": "66656bfb",
        "outputId": "a60535d4-d63e-4e2c-cf5c-0e91fc6473ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-651c14c6d32f>:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n"
          ]
        }
      ],
      "source": [
        "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7655b17a",
      "metadata": {
        "id": "7655b17a"
      },
      "source": [
        "이 객체는 build_model() 함수로 만들어진 케라스 모델을 감싸는 간단한 래퍼입니다.<br>\n",
        "이 객체를 만들 때 어떤 하이퍼파라미터도 정의하지 않았으므로 build_model()에 정의된 기본 파라미터를 사용할 것입니다.\n",
        "\n",
        "이제 일반적 사이킷런 회귀 추정기처럼 이 객체를 사용할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "157647be",
      "metadata": {
        "scrolled": true,
        "id": "157647be",
        "outputId": "fc846c33-fa28-4b1e-99af-b4a395a9bdab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 1.0896 - val_loss: 20.7721\n",
            "Epoch 2/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.7606 - val_loss: 5.0266\n",
            "Epoch 3/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5456 - val_loss: 0.5490\n",
            "Epoch 4/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4732 - val_loss: 0.4529\n",
            "Epoch 5/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4503 - val_loss: 0.4188\n",
            "Epoch 6/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4338 - val_loss: 0.4129\n",
            "Epoch 7/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4241 - val_loss: 0.4004\n",
            "Epoch 8/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4168 - val_loss: 0.3944\n",
            "Epoch 9/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4108 - val_loss: 0.3961\n",
            "Epoch 10/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4060 - val_loss: 0.4071\n",
            "Epoch 11/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4021 - val_loss: 0.3855\n",
            "Epoch 12/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3984 - val_loss: 0.4136\n",
            "Epoch 13/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3951 - val_loss: 0.3997\n",
            "Epoch 14/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3921 - val_loss: 0.3818\n",
            "Epoch 15/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3894 - val_loss: 0.3829\n",
            "Epoch 16/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3869 - val_loss: 0.3739\n",
            "Epoch 17/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3848 - val_loss: 0.4022\n",
            "Epoch 18/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3829 - val_loss: 0.3873\n",
            "Epoch 19/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3807 - val_loss: 0.3768\n",
            "Epoch 20/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3791 - val_loss: 0.4191\n",
            "Epoch 21/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3774 - val_loss: 0.3927\n",
            "Epoch 22/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3756 - val_loss: 0.4237\n",
            "Epoch 23/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3742 - val_loss: 0.3523\n",
            "Epoch 24/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3725 - val_loss: 0.3842\n",
            "Epoch 25/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3710 - val_loss: 0.4162\n",
            "Epoch 26/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3700 - val_loss: 0.3980\n",
            "Epoch 27/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3691 - val_loss: 0.3473\n",
            "Epoch 28/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3677 - val_loss: 0.3921\n",
            "Epoch 29/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3670 - val_loss: 0.3566\n",
            "Epoch 30/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3653 - val_loss: 0.4191\n",
            "Epoch 31/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3647 - val_loss: 0.3722\n",
            "Epoch 32/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3633 - val_loss: 0.3948\n",
            "Epoch 33/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3632 - val_loss: 0.3423\n",
            "Epoch 34/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3617 - val_loss: 0.3454\n",
            "Epoch 35/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3610 - val_loss: 0.4068\n",
            "Epoch 36/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3608 - val_loss: 0.3417\n",
            "Epoch 37/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3596 - val_loss: 0.3787\n",
            "Epoch 38/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3589 - val_loss: 0.3379\n",
            "Epoch 39/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3582 - val_loss: 0.3419\n",
            "Epoch 40/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3572 - val_loss: 0.3705\n",
            "Epoch 41/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3570 - val_loss: 0.3660\n",
            "Epoch 42/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3563 - val_loss: 0.3803\n",
            "Epoch 43/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3552 - val_loss: 0.3766\n",
            "Epoch 44/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3548 - val_loss: 0.3814\n",
            "Epoch 45/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3543 - val_loss: 0.3326\n",
            "Epoch 46/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3532 - val_loss: 0.3385\n",
            "Epoch 47/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3527 - val_loss: 0.3657\n",
            "Epoch 48/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3521 - val_loss: 0.3576\n",
            "Epoch 49/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3525 - val_loss: 0.3358\n",
            "Epoch 50/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3510 - val_loss: 0.3317\n",
            "Epoch 51/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3504 - val_loss: 0.3564\n",
            "Epoch 52/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3502 - val_loss: 0.3522\n",
            "Epoch 53/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3496 - val_loss: 0.4581\n",
            "Epoch 54/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3497 - val_loss: 0.3808\n",
            "Epoch 55/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3490 - val_loss: 0.3539\n",
            "Epoch 56/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3485 - val_loss: 0.3721\n",
            "Epoch 57/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3479 - val_loss: 0.3336\n",
            "Epoch 58/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3470 - val_loss: 0.4011\n",
            "Epoch 59/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3475 - val_loss: 0.3263\n",
            "Epoch 60/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3465 - val_loss: 0.3271\n",
            "Epoch 61/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3452 - val_loss: 0.3348\n",
            "Epoch 62/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3453 - val_loss: 0.3492\n",
            "Epoch 63/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3444 - val_loss: 0.3401\n",
            "Epoch 64/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3450 - val_loss: 0.3274\n",
            "Epoch 65/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3437 - val_loss: 0.3296\n",
            "Epoch 66/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3431 - val_loss: 0.3307\n",
            "Epoch 67/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3428 - val_loss: 0.3252\n",
            "Epoch 68/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3423 - val_loss: 0.3242\n",
            "Epoch 69/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3419 - val_loss: 0.3254\n",
            "Epoch 70/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3413 - val_loss: 0.3659\n",
            "Epoch 71/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3414 - val_loss: 0.3379\n",
            "Epoch 72/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3405 - val_loss: 0.3272\n",
            "Epoch 73/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3399 - val_loss: 0.3242\n",
            "Epoch 74/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3402 - val_loss: 0.3661\n",
            "Epoch 75/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3397 - val_loss: 0.3284\n",
            "Epoch 76/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3394 - val_loss: 0.3243\n",
            "Epoch 77/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3383 - val_loss: 0.3372\n",
            "Epoch 78/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3384 - val_loss: 0.3366\n",
            "162/162 [==============================] - 0s 2ms/step - loss: 0.3412\n",
            "1/1 [==============================] - 0s 91ms/step\n"
          ]
        }
      ],
      "source": [
        "keras_reg.fit(X_train, y_train, epochs=100,\n",
        "             validation_data=(X_valid, y_valid),\n",
        "             callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
        "mse_test = keras_reg.score(X_test, y_test)\n",
        "y_pred = keras_reg.predict(X_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51755c3a",
      "metadata": {
        "id": "51755c3a"
      },
      "source": [
        "fit() 메소드에 지정한 모든 매개변수는 케라스 모델로 전달됩니다.<br>\n",
        "사이킷런은 손실이 아니라 점수를 계산하기 때문에 출력 점수는 음수의 MSE입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e5cc898",
      "metadata": {
        "id": "3e5cc898"
      },
      "source": [
        "모델 하나를 훈련하고 평가하려는 게 아니라 수백 개의 모델을 훈련하고<br>\n",
        "검증 세트에서 최상의 성능을 보이는 모델을 선택해야 합니다.\n",
        "\n",
        "하이퍼파라미터가 많으므로 그리드탐색보다 랜덤 탐색을 사용하는 게 좋습니다.<br>\n",
        "은닉층 개수, 뉴런 개수, 학습률을 사용해 하이퍼파라미터 탐색을 해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "60f1f58c",
      "metadata": {
        "id": "60f1f58c"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import reciprocal\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26b54794",
      "metadata": {
        "scrolled": true,
        "id": "26b54794",
        "outputId": "f56e1947-1cd7-44e0-aa0b-41dad6d89065",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 3.3071 - val_loss: 1.3735\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.9782 - val_loss: 0.6881\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.6186 - val_loss: 0.5887\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5504 - val_loss: 0.5466\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5363 - val_loss: 0.5360\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5307 - val_loss: 0.7261\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5322 - val_loss: 0.6728\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5311 - val_loss: 0.6939\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5326 - val_loss: 0.5351\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5285 - val_loss: 0.7098\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5301 - val_loss: 0.7256\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5318 - val_loss: 0.5143\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5266 - val_loss: 0.7768\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5289 - val_loss: 0.8290\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5321 - val_loss: 0.5662\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5277 - val_loss: 0.6917\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5287 - val_loss: 0.7144\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5280 - val_loss: 0.7866\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5283 - val_loss: 0.8121\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5289 - val_loss: 0.7938\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5312 - val_loss: 0.5521\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5260 - val_loss: 0.7420\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.5307\n",
            "[CV] END learning_rate=0.001683454924600351, n_hidden=0, n_neurons=15; total time=  18.4s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 3.1141 - val_loss: 4.8527\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.1858 - val_loss: 5.7781\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7680 - val_loss: 7.3954\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6629 - val_loss: 9.0480\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6262 - val_loss: 10.6619\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6063 - val_loss: 12.1910\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5920 - val_loss: 13.5524\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5804 - val_loss: 14.8237\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5706 - val_loss: 15.9014\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5622 - val_loss: 16.6985\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5547 - val_loss: 17.5754\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.9629\n",
            "[CV] END learning_rate=0.001683454924600351, n_hidden=0, n_neurons=15; total time=   6.7s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 3.3292 - val_loss: 1.4882\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.0465 - val_loss: 0.7937\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6751 - val_loss: 0.6177\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5987 - val_loss: 0.8254\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5830 - val_loss: 0.5377\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5753 - val_loss: 0.6099\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5702 - val_loss: 0.6253\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5652 - val_loss: 0.8471\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5657 - val_loss: 0.6425\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5596 - val_loss: 0.5199\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5556 - val_loss: 0.8090\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5577 - val_loss: 0.5688\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5520 - val_loss: 0.5168\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5510 - val_loss: 0.6076\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5501 - val_loss: 0.5336\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5450 - val_loss: 0.7362\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5478 - val_loss: 0.5605\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5451 - val_loss: 0.5444\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5409 - val_loss: 0.8182\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5445 - val_loss: 0.6036\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5416 - val_loss: 0.5972\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5401 - val_loss: 0.6284\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5411 - val_loss: 0.5138\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5380 - val_loss: 0.5577\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5383 - val_loss: 0.5382\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5371 - val_loss: 0.4967\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5323 - val_loss: 0.8240\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5389 - val_loss: 0.5807\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5334 - val_loss: 0.7438\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5371 - val_loss: 0.6009\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5327 - val_loss: 0.6786\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5339 - val_loss: 0.7585\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5337 - val_loss: 0.7489\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5339 - val_loss: 0.8001\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5338 - val_loss: 0.7895\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5356 - val_loss: 0.5188\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.5325\n",
            "[CV] END learning_rate=0.001683454924600351, n_hidden=0, n_neurons=15; total time=  19.8s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.5376 - val_loss: 12.3982\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.0178 - val_loss: 125.6315\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.1488 - val_loss: 346.5433\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 3.6725 - val_loss: 1751.5996\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 10.3581 - val_loss: 6041.1782\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 127.6586 - val_loss: 23472.3613\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 242.6267 - val_loss: 91941.1250\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1803.9309 - val_loss: 363473.0312\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 4479.3096 - val_loss: 1426668.5000\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 31568.9824 - val_loss: 5931677.5000\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 79243.1094 - val_loss: 23249496.0000\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 61659.1211\n",
            "[CV] END learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21; total time=  10.9s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.4335 - val_loss: 4.8167\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5960 - val_loss: 14.1333\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5457 - val_loss: 20.4455\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5249 - val_loss: 21.9033\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5142 - val_loss: 22.1810\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5089 - val_loss: 22.0884\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5063 - val_loss: 21.3664\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5041 - val_loss: 21.8242\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5024 - val_loss: 20.9199\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5026 - val_loss: 17.6230\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5028 - val_loss: 19.6622\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.9656\n",
            "[CV] END learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21; total time=  10.7s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.7711 - val_loss: 187.7519\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.4834 - val_loss: 263.9903\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.1547 - val_loss: 822.8343\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 19.9118 - val_loss: 1671.0698\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 5.4077 - val_loss: 4295.0562\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 33.5804 - val_loss: 7616.0767\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 44.4470 - val_loss: 15214.2676\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 291.0752 - val_loss: 29863.5859\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 284.0782 - val_loss: 58099.7227\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 150.7682 - val_loss: 108415.1641\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2858.6553 - val_loss: 208504.5312\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 229.6740\n",
            "[CV] END learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21; total time=   6.2s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.9937 - val_loss: 2.6699\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.0723 - val_loss: 0.9824\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8178 - val_loss: 0.7381\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7416 - val_loss: 0.6810\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7010 - val_loss: 0.6511\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6717 - val_loss: 0.6305\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6476 - val_loss: 0.6165\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6270 - val_loss: 0.5872\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6083 - val_loss: 0.5622\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5907 - val_loss: 0.5500\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5750 - val_loss: 0.5370\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5605 - val_loss: 0.5184\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5465 - val_loss: 0.5108\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5340 - val_loss: 0.4944\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5222 - val_loss: 0.4824\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5109 - val_loss: 0.4729\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5008 - val_loss: 0.4628\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4912 - val_loss: 0.4545\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4823 - val_loss: 0.4471\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4743 - val_loss: 0.4391\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4668 - val_loss: 0.4353\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4598 - val_loss: 0.4273\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4535 - val_loss: 0.4214\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4474 - val_loss: 0.4161\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4424 - val_loss: 0.4135\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4373 - val_loss: 0.4126\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4328 - val_loss: 0.4066\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4285 - val_loss: 0.4135\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4244 - val_loss: 0.4058\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4208 - val_loss: 0.4016\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4174 - val_loss: 0.3951\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4141 - val_loss: 0.3946\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4112 - val_loss: 0.4012\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4084 - val_loss: 0.4010\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4059 - val_loss: 0.3899\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4034 - val_loss: 0.3990\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4012 - val_loss: 0.3843\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3990 - val_loss: 0.4004\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3970 - val_loss: 0.3831\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3951 - val_loss: 0.3933\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3932 - val_loss: 0.3921\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3914 - val_loss: 0.3846\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3899 - val_loss: 0.3781\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3880 - val_loss: 0.4054\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3868 - val_loss: 0.3857\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3851 - val_loss: 0.3808\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3839 - val_loss: 0.3979\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3825 - val_loss: 0.3844\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3812 - val_loss: 0.3851\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3799 - val_loss: 0.3993\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3787 - val_loss: 0.3877\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3779 - val_loss: 0.3881\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3766 - val_loss: 0.3952\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3925\n",
            "[CV] END learning_rate=0.0006154014789262348, n_hidden=2, n_neurons=87; total time=  33.8s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.5809 - val_loss: 4.4401\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9454 - val_loss: 5.4218\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7935 - val_loss: 4.0185\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7312 - val_loss: 2.8357\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6912 - val_loss: 2.0552\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6607 - val_loss: 1.5100\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6346 - val_loss: 1.1061\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6115 - val_loss: 0.8217\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5908 - val_loss: 0.6628\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5723 - val_loss: 0.5671\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5554 - val_loss: 0.5271\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5401 - val_loss: 0.5376\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5265 - val_loss: 0.5763\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5143 - val_loss: 0.6084\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5033 - val_loss: 0.6868\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4934 - val_loss: 0.7318\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4845 - val_loss: 0.7987\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4766 - val_loss: 0.8501\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4693 - val_loss: 0.9150\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4628 - val_loss: 0.9426\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4568 - val_loss: 1.0091\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.4903\n",
            "[CV] END learning_rate=0.0006154014789262348, n_hidden=2, n_neurons=87; total time=  21.2s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.8794 - val_loss: 1.5758\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.0443 - val_loss: 0.9371\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7631 - val_loss: 0.6947\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6827 - val_loss: 0.6333\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6429 - val_loss: 0.5996\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6160 - val_loss: 0.5759\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5939 - val_loss: 0.5595\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5755 - val_loss: 0.5655\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5596 - val_loss: 0.5242\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5446 - val_loss: 0.5085\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5309 - val_loss: 0.5008\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5186 - val_loss: 0.4841\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5069 - val_loss: 0.4731\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4964 - val_loss: 0.4638\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4866 - val_loss: 0.4547\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4777 - val_loss: 0.4472\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4695 - val_loss: 0.4386\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4619 - val_loss: 0.4320\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4551 - val_loss: 0.4272\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4489 - val_loss: 0.4190\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4430 - val_loss: 0.4132\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4377 - val_loss: 0.4099\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4329 - val_loss: 0.4044\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4281 - val_loss: 0.4054\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4242 - val_loss: 0.3960\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4202 - val_loss: 0.3926\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4165 - val_loss: 0.3891\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4132 - val_loss: 0.3874\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4098 - val_loss: 0.3892\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4072 - val_loss: 0.3820\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4041 - val_loss: 0.3779\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4016 - val_loss: 0.3812\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3988 - val_loss: 0.3750\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3966 - val_loss: 0.3852\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3946 - val_loss: 0.3721\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3922 - val_loss: 0.3701\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3904 - val_loss: 0.3688\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3884 - val_loss: 0.3729\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3865 - val_loss: 0.3652\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3847 - val_loss: 0.3641\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3828 - val_loss: 0.3779\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3816 - val_loss: 0.3731\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3797 - val_loss: 0.3582\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3785 - val_loss: 0.3664\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3769 - val_loss: 0.3623\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3756 - val_loss: 0.3618\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3742 - val_loss: 0.3541\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3730 - val_loss: 0.3548\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3716 - val_loss: 0.3714\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3706 - val_loss: 0.3679\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3693 - val_loss: 0.3644\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3683 - val_loss: 0.3684\n",
            "Epoch 53/100\n",
            "213/242 [=========================>....] - ETA: 0s - loss: 0.3651"
          ]
        }
      ],
      "source": [
        "param_distribs = {\n",
        "    'n_hidden': [0, 1, 2, 3],\n",
        "    'n_neurons': np.arange(1, 100),\n",
        "    'learning_rate': reciprocal(3e-4, 3e-2)\n",
        "}\n",
        "\n",
        "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
        "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
        "                 validation_data=(X_valid, y_valid),\n",
        "                 callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c06d2ea6",
      "metadata": {
        "id": "c06d2ea6"
      },
      "source": [
        "RandomizedSearchCV는 k-겹 교차 검증을 사용하기 때문에 X_valid와 y_valid를 사용하지 않습니다.<br>\n",
        "이 데이터는 조기 종료 시에만 사용됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00f0b351",
      "metadata": {
        "id": "00f0b351"
      },
      "source": [
        "다음은 하이퍼파라미터 최적화에 사용할 수 있는 다른 파이썬 라이브러리들입니다.\n",
        "\n",
        "- Hyperopt\n",
        "- Hyperas, kopt, Talos\n",
        "- Keras Tuner\n",
        "- Scikit-Optimize(skopt)\n",
        "- Spearmint\n",
        "- Hyperband\n",
        "- Sklearn-Deap"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}